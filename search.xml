<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[js模块化发展历程]]></title>
    <url>%2F%E5%89%8D%E7%AB%AF%E7%AC%94%E8%AE%B0%2Fjs%E6%A8%A1%E5%9D%97%E5%8C%96%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[模块化是指把一个复杂的系统分解到一个一个的模块。 模块化开发的优点：(1)代码复用，让我们更方便地进行代码管理、同时也便于后面代码的修改和维护。 (2)一个单独的文件就是一个模块，是一个单独的作用域，只向外暴露特定的变量和函数。这样可以避免污染全局变量，减少变量命名冲突。 js模块化规范有：CommonJS、AMD、CMD、ES6的模块系统。本文将依次介绍下每个规范。 一、早期：用script来引入js模块1234&lt;script type="text/javascript" src="a.js"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="b.js"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="c.js"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="d.js"&gt;&lt;/script&gt; 缺点：(1)加载的时候会停止渲染网页，引入的js文件越多，网页失去响应的时间越长； (2)会污染全局变量； (3)js文件之间存在依赖关系，加载是有顺序的，依赖性最大的要放到最后去加载；当项目规模较大时，依赖关系变得错综复杂。 (4)要引入的js文件太多，不美观，代码难以管理。 二、CommonJS 规范是服务器端模块的规范，由nodejs推广使用。该规范的核心思想是：允许模块通过require方法来同步加载所要依赖的其他模块，然后通过 exports 或module.exports 来导出需要暴露的接口。 CommonJS 还可以细分为 CommonJS1 和 CommonJS2，区别在于 CommonJS1 只能通过 exports.xx = xx 的方式导出，CommonJS2 在 CommonJS1 的基础上加入了module.exports = xx 的导出方式。 CommonJS 通常指 CommonJS2。 采用CommonJS 规范导入导出： 1234// 导出module.exports = moduleA.someFunc;// 导入const moduleA = require('./moduleA'); 实例： 12345678910//math.jsvar num = 0;function add(a, b) &#123; return a + b;&#125;module.exports = &#123; //需要向外暴露的变量、函数 num: num, add: add&#125; 可以这样加载： 1234//引入自定义的模块时，参数包含路径，可省略.js//引入核心模块时，不需要带路径，如var http = require("http");var math = require('./math');math.add(1, 2)//3 实际上，从上面的例子就可以看出，math.add(1,2)必须要等待math.js加载完成，即require是同步的。 在服务器端，模块文件保存在本地磁盘，等待时间就是磁盘的读取时间。但对于浏览器而言，由于模块都放在服务器端，等待时间取决于网上的快慢。因此更合理的方案是异步加载模块。 缺点：(1)不能并行加载模块，会阻塞浏览器加载； (2)代码无法直接运行在浏览器环境下，必须通过工具转换成标准的 ES5； 三、AMD和require.jsAMD：异步模块定义。上面已经介绍过，CommonJS是服务器端模块的规范，主要是为了JS在后端的表现制定的，不太适合前端。而AMD就是要为前端JS的表现制定规范。由于不是JavaScript原生支持，使用AMD规范进行页面开发需要用到对应的库函数，也就是require.js（还有个js库：curl.js）。实际上AMD 是 require.js在推广过程中对模块定义的规范化的产出。 AMD采用异步方式加载模块，模块的加载不影响它后面语句的运行。所有依赖这个模块的语句，都定义在一个回调函数中，等到加载完成之后，这个回调函数才会运行。 require.js也采用require()语句加载模块，但是不同于CommonJS： 12345678// 定义一个模块define('module', ['dep'], function (dep) &#123; return exports;&#125;);// 导入和使用require(['module'], function (module) &#123;&#125;); 上面示例中的代码改写成AMD形式： math.js定义一个模块: 1234567define('math', ['jquery'], function (jquery) &#123;//引入jQuery模块 return &#123; add: function (x, y) &#123; return x + y; &#125; &#125;;&#125;); 导入和使用： 123require(['math'], function (math) &#123; math.add(1, 2)&#125;) math.add()与加载math模块不是同步的，不会阻塞浏览器的加载。 四、CMD和sea.jsCMD：通用模块定义。 国内的玉伯大佬写了sea.js，实际上CMD就是 sea.js在推广过程中对模块定义的规范化的产出。 123define(function (require, exports, module) &#123; // 模块代码&#125;); 说明： require：可以把其他模块导入进来的一个参数； exports：可以把模块内的一些属性和方法导出的； module： 是一个对象，上面存储了与当前模块相关联的一些属性和方法。 上面示例中的代码改写成AMD形式： 1234567891011define(function (require, exports, module) &#123; var add = function (a, b) &#123; return a + b; &#125; exports.add = add;&#125;)//导入和使用seajs.use(['math.js'], function (math) &#123; var sum = math.add(1, 2);&#125;); CMD与AMD的不同的在于：(1)AMD推崇依赖前置；CMD推崇依赖就近，只有在用到某个模块的时候再去require： 12345678910111213141516171819//AMD推崇的依赖关系前置：在定义模块时就要声明要依赖的模块define(['a', 'b', 'c', 'd'], function (a, b, c, d) &#123; // 依赖必须一开始就写好 a.doSomething() // 此处省略100行 ... b.doSomething() ...&#125;)//CMD推崇依赖就近，按需加载，只有在用到某个模块时再去requiredefine(function (require, exports, modules) &#123; var a = require('a'); a.doSomething(); // 此处省略100行 ... var b = require("b");//按需加载 b.doSomething(); ...&#125;) (2)AMD 的 API 默认是一个当多个用，CMD 的 API 严格区分，推崇职责单一。 对于依赖的模块，AMD是提前执行，CMD是延迟执行。 具体细节可点击与 RequireJS 的异同 五、ES6模块化ES6在语言的层面上实现了模块化。浏览器厂商和 Node.js 都宣布要原生支持该规范。它将逐渐取代 CommonJS 和 AMD 规范，成为浏览器和服务器通用的模块解决方案。 在 ES6 中，使用export关键字来导出模块，使用import关键字引用模块。但是浏览器还没有完全兼容，需要使用babel转换成ES5。 12345678// 导出export function hello() &#123; &#125;;export default &#123; // ...&#125;;// 导入import &#123; readFile &#125; from 'fs';import React from 'react'; 使用import导入模块时，需要知道要加载的变量名或函数名。 在ES6中还提供了export default，为模块指定默认输出.对应导入模块import时，不需要使用大括号。 上面示例中的代码改写成ES6形式： 123456789101112//math.jsvar num = 0;var add = function (a, b) &#123; return a + b;&#125;;export &#123; num, add &#125;;//导入import &#123; num, add &#125; from './math';function test(ele) &#123; ele.textContent = add(1 + num);&#125; 缺点浏览器还没有完全兼容，必须通过工具转换成标准的 ES5 后才能正常运行。 小结本文从script引入js文件讲起，到服务器端模块的规范CommonJs，再到推崇依赖前置的浏览器端模块的规范AMD、推崇依赖就近的浏览器端模块的规范CMD，最后介绍了ES6的模块化。每个介绍中都有各规范基本的用法和一个示例。如有问题，欢迎指正。]]></content>
      <categories>
        <category>前端笔记</category>
      </categories>
      <tags>
        <tag>javascript</tag>
        <tag>模块化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用hexo-asset-image插件引用本地图片无法显示]]></title>
    <url>%2F%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%2F%E4%BD%BF%E7%94%A8hexo-asset-image%E6%8F%92%E4%BB%B6%E5%BC%95%E7%94%A8%E6%9C%AC%E5%9C%B0%E5%9B%BE%E7%89%87%E6%97%A0%E6%B3%95%E6%98%BE%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[启用文章资源文件夹功能： 1.修改站点配置文件_config.yml：post_asset_folder: true 2.安装一个可以上传本地图片的插件：npm install hexo-asset-image --save 3.以后使用hexo new &#39;xxxx&#39;来生成md博文时，/source/_posts文件夹内除了xxxx.md文件还有一个同名的文件夹 4.当我们在xxxx.md中想引入图片时，先把图片复制到xxxx这个文件夹中，然后只需要在xxxx.md中按照markdown的格式引入图片：![](图片名.jpg) 在文章里面插入图片，hexo g生成的时候总会在图片前面插一个.io，hexo s运行后图片并没有正常显示出来，在网上查找后发现是hexo-asset-image这个插件的bug，hexo版本3.0以上获取网站url的方式与3.0以下有些不同。 解决办法：打开/node_modules/hexo-asset-image/index.js，将内容更换为下面的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061'use strict';var cheerio = require('cheerio');// http://stackoverflow.com/questions/14480345/how-to-get-the-nth-occurrence-in-a-stringfunction getPosition(str, m, i) &#123; return str.split(m, i).join(m).length;&#125;var version = String(hexo.version).split('.');hexo.extend.filter.register('after_post_render', function(data)&#123; var config = hexo.config; if(config.post_asset_folder)&#123; var link = data.permalink; if(version.length &gt; 0 &amp;&amp; Number(version[0]) == 3) var beginPos = getPosition(link, '/', 1) + 1; else var beginPos = getPosition(link, '/', 3) + 1; // In hexo 3.1.1, the permalink of "about" page is like ".../about/index.html". var endPos = link.lastIndexOf('/') + 1; link = link.substring(beginPos, endPos); var toprocess = ['excerpt', 'more', 'content']; for(var i = 0; i &lt; toprocess.length; i++)&#123; var key = toprocess[i]; var $ = cheerio.load(data[key], &#123; ignoreWhitespace: false, xmlMode: false, lowerCaseTags: false, decodeEntities: false &#125;); $('img').each(function()&#123; if ($(this).attr('src'))&#123; // For windows style path, we replace '\' to '/'. var src = $(this).attr('src').replace('\\', '/'); if(!/http[s]*.*|\/\/.*/.test(src) &amp;&amp; !/^\s*\//.test(src)) &#123; // For "about" page, the first part of "src" can't be removed. // In addition, to support multi-level local directory. var linkArray = link.split('/').filter(function(elem)&#123; return elem != ''; &#125;); var srcArray = src.split('/').filter(function(elem)&#123; return elem != '' &amp;&amp; elem != '.'; &#125;); if(srcArray.length &gt; 1) srcArray.shift(); src = srcArray.join('/'); $(this).attr('src', config.root + link + src); console.info&amp;&amp;console.info("update link as:--&gt;"+config.root + link + src); &#125; &#125;else&#123; console.info&amp;&amp;console.info("no src attr, skipped..."); console.info&amp;&amp;console.info($(this)); &#125; &#125;); data[key] = $.html(); &#125; &#125;&#125;);]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运行gulp项目报错：AssertionError [ERR_ASSERTION]: Task function must be specified]]></title>
    <url>%2F%E5%89%8D%E7%AB%AF%E7%AC%94%E8%AE%B0%2F%E8%BF%90%E8%A1%8Cgulp%E9%A1%B9%E7%9B%AE%E6%8A%A5%E9%94%99%EF%BC%9AAssertionError-ERR-ASSERTION-Task-function-must-be-specified%2F</url>
    <content type="text"><![CDATA[今天写了一篇文章正准备发布，生成静态资源文件后使用gulp bulid压缩代码，但是一运行：gulp 出现了这个错误： 12345678910111213141516$ gulp buildassert.js:339 throw err; ^AssertionError [ERR_ASSERTION]: Task function must be specified at Gulp.set [as _setTask] (E:\Documents\GitHub\blog\node_modules\undertaker\lib\set-task.js:10:3) at Gulp.task (E:\Documents\GitHub\blog\node_modules\undertaker\lib\task.js:13:8) at Object.&lt;anonymous&gt; (E:\Documents\GitHub\blog\gulpfile.js:43:6) at Module._compile (internal/modules/cjs/loader.js:776:30) at Object.Module._extensions..js (internal/modules/cjs/loader.js:787:10) at Module.load (internal/modules/cjs/loader.js:653:32) at tryModuleLoad (internal/modules/cjs/loader.js:593:12) at Function.Module._load (internal/modules/cjs/loader.js:585:3) at Module.require (internal/modules/cjs/loader.js:690:17) at require (internal/modules/cjs/helpers.js:25:18) gulp项目需要全局安装gulp和项目内安装gulp 通过 gulp -v 查看全局gulp 和本地项目的gulp版本： 123$ gulp -vCLI version: 3.9.1Local version: 4.0.2 查看package.json文件果然：&quot;gulp&quot;: &quot;^4.0.2&quot;, 因为本地的gulp更新到了版本4，而gulpfile.js用的是gulp3.9.1的语法 解决方案一：npm i gulp@3.9.1 重新安装gulp到3.9.1版 解决方案二：按gulp4的语法重写gulpfile.js任务列表]]></content>
      <categories>
        <category>前端笔记</category>
      </categories>
      <tags>
        <tag>javascript</tag>
        <tag>gulp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OffscreenCanvas - 概念说明及使用解析]]></title>
    <url>%2F%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2FOffscreenCanvas-%E6%A6%82%E5%BF%B5%E8%AF%B4%E6%98%8E%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[OffscreenCanvas 是一个实验中的新特性，主要用于提升 Canvas 2D/3D 绘图应用和 H5 游戏的渲染性能和使用体验。OffscreenCanvas 的 API 很简单，但是要真正掌握好如何使用，需要页端对浏览器内部的一些运作机制有较深入的了解，这也是撰写本文的目的。 跟 OffscreenCanvas 关系比较紧密的还有另外两个新的 API，ImageBitmap 和 ImageBitmapRenderingContext，在文中也会一并进行讲解。 目前 OffscreenCanvas 在最新版本的 Chrome 和 Firefox 上都可以通过实验室开关打开，Chrome 的开关是 chome://flags -&gt; Experimental Web Platform features，本文的例程是在 Chrome 67 Canary 上进行验证。OffscreenCanvas 的 API 在未来仍有可能会发生一些变化，本文会随之进行更新。 概念说明Chrome 开发文档里面对 OffscreenCanvas 的定义是： A new interface that allows canvas rendering contexts (2D and WebGL) to be used in workers.Making canvas rendering contexts available to workers will increase parallelism in web applications, leading to increased performance on multi-core systems. 简单的说，就是你现在可以在 Worker 线程调用 Canvas API 啦，通过在 Worker 线程完成 Canvas 渲染任务，可以提升 WebApp 的并发程度，从而提升性能和使用体验，balabala… 不过 JavaScript 目前并没有提供一个真正可用的多线程并发编程模型，缺少了互斥，信号量等同步原语，线程间无法共享数据，所以除了一些很特定的应用场景，并且需要页端对应用/游戏的引擎设计做出较大的修改，大部分场景下指望简单地使用 OffscreenCanvas 然后就能获得并发带来的大幅性能提升其实并不太现实。不过即使应用/游戏无法有效地使用 OffscreenCanvas 来实现自身的多线程并发运行，OffscreenCanvas 仍然提供了很高的使用价值，也让浏览器有机会优化自身的 Canvas 渲染流水线，下文会通过例程来讲解如何在实际的应用场景中有效地使用 OffscreenCanvas。 当然你还是可以在主线程使用 OffscreenCanvas，并且即使在主线程使用，取决于应用的场景，也还是可能会带来一些收益。JavaScript 未来也许会增加多线程共享数据，数据访问同步的支持，但是起码目前是没有的。 使用解析OffscreenCanvas 目前主要用于两种不同的使用场景： 一种是在 Worker 线程创建一个 OffscreenCanvas 做后台渲染，然后再把渲染好的缓冲区 Transfer 回主线程显示； 一种是主线程从当前 DOM 树中的 Canvas 元素产生一个 OffscreenCanvas，再把这个 OffscreenCanvas 发送给 Worker 线程进行渲染，渲染的结果直接 Commit 到浏览器的 Display Compositor 输出到当前窗口，相当于在 Worker 线程直接更新 Canvas 元素的内容； 我自己把第一种使用方式称之为 Transfer 模式，第二种使用方式称之为 Commit 模式。 Transfer 模式 Transfer Demo，使用 Transfer 模式 Transfer 模式主要用于后台渲染，避免耗时的渲染任务会阻塞前台线程，导致应用无法及时响应用户的操作，比如一些 2D/3D 图表，图形可视化应用，地图应用等。 实际上这是 OffscreenCanvas 这个特性的最早需求，来自于 Google Map 团队。 Transfer Demo 运行流程大致如下： 主线程启动 Worker 线程，并请求初始化； Worker 线程创建 OffscreenCanvas； Worker 线程获取 OffscreenCanvas 的 WebGL Context 并进行绘制； Worker 线程获取 OffscreenCanvas 的缓冲区（ImageBitmap），然后 Transfer 回主线程； 主线程将 Worker 线程回传的缓冲区分别绘制在两个不同的 Canvas 上，一个 Canvas 使用 CanvasRenderingContext2D，一个 Canvas 使用 ImageBitmapRenderingContext； 3 ~ 5 重复运行； 代码解析下面是一些主要步骤的代码，展示了 OffscreenCanvas，ImageBitmap，ImageBitmapRenderingContext API 的使用。 在 Worker 线程创建 OffscreenCanvas 12345function Init(mode, data) &#123; if (mode === "transfer") canvas = new OffscreenCanvas(data.width, data.height); ...&#125; 获取 OffscreenCanvas 的缓冲区并回传 12345function TransferBuffer() &#123; let image_bitmap = canvas.transferToImageBitmap(); postMessage(&#123;name:"TransferBuffer", buffer:image_bitmap&#125;, [image_bitmap]);&#125; 主线程接收回传的缓冲区并绘制 12345678910111213141516171819g_render_worker.onmessage = function(msg) &#123; if (msg.data.name === "TransferBuffer") &#123; GetTransferBuffer(msg.data.buffer); &#125;&#125;function GetTransferBuffer(buffer) &#123; let context_2d = g_2d_canvas.getContext("2d"); context_2d.clearRect(0, 0, g_2d_canvas.width, g_2d_canvas.height); context_2d.save(); ... context_2d.drawImage(buffer, 0, 0); context_2d.restore(); ... let bitmap_context = g_bitmap_canvas.getContext("bitmaprenderer"); bitmap_context.transferFromImageBitmap(buffer);&#125; ImageBitmap 和 ImageBitmapRenderingContext上面的例程使用到了 ImageBitmap 和 ImageBitmapRenderingContext，它们到底是什么，跟 ImageData 和 CanvasRenderingContext2D 又有什么不同？ ImageBitmap 主要是用来封装一块 GPU 缓冲区，可以被 GPU 读写，并且实现了 Transferable 的接口，可以在不同线程之间 Transfer。跟 ImageData 不一样，ImageBitmap 并没有提供 JavaScipt API 供 CPU 进行读写，这是因为使用 CPU 读写 GPU 缓冲区的成本非常高，需要拷贝到临时缓冲区进行读写然后再写回。这也是为什么规范的制定者没有扩展 ImageData，而是提供了一个新的 ImageBitmap 的缘故。 ImageBitmap 可以被当做普通的 Image 绘制在一个 2D Canvas 上，也可以通过 ImageBitmapRenderingContext Transfer 到一个 Bitmap Canvas，我们通过举例来说明这两种方式的区别： 但我们使用 OffscreenCanvas，通过 2D/3D 进行绘制时，就好像我们有一块画板，上面有一些画纸，我们可以在画纸上作画； 调用 OffscreenCanvas.transferToImageBitmap 获取 ImageBitmap 封装的缓冲区，就好像我们把当前绘画的画纸取下来； 把 ImageBitmap 作为 Image 绘制在一个 2D Canvas 上，就好像我们对已经绘制好的图画在新的画纸上进行临摹； 把 ImageBitmap 通过 ImageBitmapRenderingContext.transferFromImageBitmap Transfer 给 Bitmap Canvas，就好像我们把画纸放入一个画框里挂在墙上显示； 简单的说 ImageBitmap Transfer 语义实现了 Zero Copy 的所有权转移，不需要对缓冲区进行拷贝，性能更高，但是也限制了显示的方式，而临摹意味着我们可以对临摹的副本进行旋转，缩放，位移等等，还可以在上面再绘制其它内容。另外 ImageBitmap Transfer 之后所有权就发生了转移，比如 Transfer Demo 的例程调换一下两个 Canvas 的绘制顺序就会报错，这是因为 Transfer 之后，原来的缓冲区引用已经被置空变成一个空引用。 具体使用哪种方式取决于应用的场景，如果只是简单的展现就可以考虑使用性能更高 ImageBitmapRenderingContext，OffscreenCanvas，加 ImageBitmap，加 ImageBitmapRenderingContext 提供了一种最高效的后台渲染，前台展现的方式。 Commit 模式Commit 模式主要用于 H5 游戏，它允许应用/游戏在 Worker 线程直接对 DOM 树里面的 Canvas 元素进行更新，浏览器在这种模式下提供了一条最短路径和最佳性能的 Canvas 渲染流水线。 要理解浏览器所做的优化，我们首先要了解普通 Canvas 元素更新的渲染流水线，跟其它 DOM 元素一样，Canvas 元素的更新也是走非合成器动画的渲染流水线，主要的缺点是： 非合成器动画的渲染流水线比较复杂和冗长，有较多的 Overhead，页面的结构越复杂，Overhead 就越高； 如果同时有其它 DOM 元素一起更新，Canvas 的更新会被其它 DOM 元素的光栅化所阻塞，导致性能下降，性能下降的幅度取决于其它 DOM 元素光栅化的耗时； 如果我们调用 Commit，并且 Commit 的 OffscreenCanvas 是跟当前 DOM 树里面的某个 Canvas 元素相关联，浏览器就会直接将 OffscreenCanvas 的当前绘制缓冲区发送给 Display Compositor，然后 Display Compositor 就会合成新的一帧输出到当前窗口，对浏览器来说这就是最短的渲染路径。 在 Worker 线程使用 Commit 模式，理论上我们会： 避免被主线程的其它任务所阻塞，Worker 线程可以完全专注在 Canvas 动画的运行上； 通过 OffscreenCanvas 更新 Canvas 元素，浏览器走的是最短的渲染路径，避免了非合成器动画的冗长流水线和 Overhead； 如果有其它 DOM 元素同时更新，不会阻塞 OffscreenCanvas 的更新，所以通过 OffscreenCanvas，的确实现了 Canvas 更新和其它 DOM 更新的并发运行； 如果 DOM 元素需要处理事件，这些事件处理不会被 Worker 线程所阻塞，只是处理的结果数据可能需要发送给 Worker 线程用于后续的绘制； 使用 OffscreenCanvas Commit 模式的副作用是 OffscreenCanvas 的更新和其它 DOM 元素的更新不再是强制同步的，即使它们是同时更新，甚至都在主线程而不使用 Worker 线程，因为两者已经分别走了不同的流水线，最后呈现在屏幕的时机也可能不会完全一致。如果一定要求同步，就只能参考 Transfer Demo 的做法，将绘制后的缓冲区 Transfer 给 Bitmap Canvas 来显示，但是这样就无法发挥 Commit 模式的性能优势了。 如果页面除了一个 Canvas 元素外没有其它 DOM 元素，理论上 OffscreenCanvas 能够带来的性能提升也比较有限，当然蚊子肉再少也是肉，能提升一点也是好的。 Commit Demo 的运行流程大致如下： 主线程从当前 DOM 树中的 Canvas 元素生成 OffscreenCanvas； 主线程启动 Worker 线程并初始化，OffscreenCanvas 作为初始化的参数被 Transfer； Worker 线程接收 OffscreenCanvas 后完成初始化； Worker 线程使用 WebGL 对 OffscreenCanvas 进行绘制； Worker 线程绘制完成后 Commit，然后等待浏览器的回调； Worker 线程接收到到浏览器的回调后继续绘制下一帧，重复 4 ~ 6； 代码解析启动 Worker 线程并初始化 12345g_render_worker = new Worker("../common/render.js");let offscreen = g_offscreen_canvas.transferControlToOffscreen();g_render_worker.postMessage( &#123;name:"Init", mode:"commit", canvas:offscreen&#125;, [offscreen]); Commit 然后等待回调 12345678function renderloop() &#123; // Render buffer first render(); // Wait next begin frame to loop gl.commit().then(renderloop);&#125;renderloop(); 动画驱动在 Worker 线程驱动 OffscreenCanvas 动画有很多方式，比如使用传统的 Timer 和 rAF 的方式。 如果使用 Timer，我们可以在 Worker 线程直接使用，参考 Transfer Demo 的例子； 如果使用 rAF，我们需要在主线程先获得 rAF 回调，然后再通知 Worker 线程； 这两种方式各有其缺陷，都不是理想的选择。 上面的例程展示了新的动画方式，gl.commit() 返回了一个 Promise 对象，它会在下一次 Begin Frame 时被 resolve，Begin Frame 基本上可以认为是浏览器环境下的 vSync 信号，浏览器会在 Begin Frame 的过程中调用 rAF 的回调，resolve Commit Promise。因为目前 Worker 线程并不支持 rAF，所以后者就是我们当前最好的选择。]]></content>
      <categories>
        <category>性能优化</category>
      </categories>
      <tags>
        <tag>Canvas</tag>
        <tag>OffscreenCanvas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OffscreenCanvas - 使用Web Worker加速您的Canvas操作]]></title>
    <url>%2F%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2FOffscreenCanvas-%E4%BD%BF%E7%94%A8Web-Worker%E5%8A%A0%E9%80%9F%E6%82%A8%E7%9A%84Canvas%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[现在，您可以使用OffscreenCanvas从主线程渲染图形！ Canvas是一种在屏幕上绘制各种图形的流行方式，也是WebGL世界的切入点。它可用于绘制形状，图像，运行动画，甚至显示和处理视频内容。它通常用于在富媒体网络应用程序和在线游戏中创建出色的用户体验。 它是可编写脚本的，这意味着画布上绘制的内容可以通过编程方式创建，例如，在JavaScript中。这赋予画布很大的灵活性。 同时，在现代网站中，脚本执行是用户响应问题最常见的 来源之一。因为画布逻辑和渲染发生在与用户交互相同的线程上，动画中涉及的（有时很重）计算会损害应用程序的真实和感知性能。 幸运的是，OffscreenCanvas 是对这种威胁的回应！ 到目前为止，画布绘制功能与&lt;canvas&gt;元素绑定，这意味着它直接取决于DOM。顾名思义，OffscreenCanvas通过将其移出屏幕来解耦DOM和Canvas API。 由于这种解耦，OffscreenCanvas的渲染与DOM完全分离，因此在常规画布上提供了一些速度提升，因为两者之间没有同步。但更重要的是，它可以在Web Worker中使用，即使没有可用的DOM。这可以实现各种有趣的用例。 在Worker中使用OffscreenCanvasWorker 是网络的线程版本 - 它们允许您在后台运行任务。将一些脚本移动到Worker可以为应用程序提供更多空间，以便在主线程上执行用户关键任务。到目前为止，没有办法在Worker中使用Canvas API，因为没有可用的DOM。 OffscreenCanvas不依赖于DOM，因此可以使用它。在这里，我使用OffscreenCanvas来计算worker中的渐变颜色： 12345678910111213141516// file: worker.jsfunction getGradientColor(percent) &#123; const canvas = new OffscreenCanvas(100, 1); const ctx = canvas.getContext('2d'); const gradient = ctx.createLinearGradient(0, 0, canvas.width, 0); gradient.addColorStop(0, 'red'); gradient.addColorStop(1, 'blue'); ctx.fillStyle = gradient; ctx.fillRect(0, 0, ctx.canvas.width, 1); const imgd = ctx.getImageData(0, 0, ctx.canvas.width, 1); const colors = imgd.data.slice(percent * 4, percent * 4 + 4); return `rgba($&#123;colors[0]&#125;, $&#123;colors[1]&#125;, $&#123;colors[2]&#125;, $&#123;colors[])`;&#125;getGradientColor(40); // rgba(152, 0, 104, 255 ) 取消阻止主线程将大量计算移动到Worker时，可以释放主线程上的大量资源，这会变得更加有趣。我们可以使用transferControlToOffscreen 方法将常规画布镜像到OffscreenCanvas实例。应用于OffscreenCanvas的操作将自动在源画布上呈现。 123const offscreen = document.querySelector('canvas').transferControlToOffscreen();const worker = new Worker('myworkerurl.js');worker.postMessage(&#123; canvas: offscreen &#125;, [offscreen]); OffscreenCanvas是可转让的。除了将其指定为消息中的字段之外，还需要将其作为postMessage（转移）中的第二个参数传递，以便可以在Worker上下文中使用它。 在下面的示例中，当颜色主题发生变化时会发生“繁重计算” - 即使在快速桌面上也应该花费几毫秒。您可以选择在主线程或Worker线程上运行动画。在主线程的情况下，当繁重的任务运行时，您无法与按钮交互 - 线程被阻止。对于Worker，对UI响应性没有影响。 示例：keep-ui-responsive 它也是另一种方式：繁忙的主线程不会影响在worker上运行的动画。尽管有主要的线程流量，您仍可以使用此功能来避免视觉抖动并保证流畅的动画： 示例 在常规画布的情况下，当主线程被人为地过度工作时动画停止，而基于Worker的OffscreenCanvas播放顺利。 与流行的库一起使用由于OffscreenCanvas API通常与常规Canvas元素兼容，因此您可以轻松地将其用作渐进增强功能，也可以使用市场上的一些领先图形库。 例如，您可以对其进行功能检测，如果可用，通过在渲染器构造函数中指定canvas选项将其与Three.js一起使用： 1234const canvasEl = document.querySelector("canvas");const canvas = ('OffscreenCanvas' in window) ? canvasEl.transferControlToOffscreen() : canvasEl;canvas.style = &#123; width: 0, height: 0 &#125;const renderer = new THREE.WebGLRenderer(&#123; canvas: canvas &#125;); 这里的问题是Three.js希望canvas具有style.width和style.height属性。OffscreenCanvas，与DOM完全分离，没有它，因此您需要自己提供它，或者通过将其删除或提供将这些值与原始画布尺寸相关联的逻辑。 这是一个如何在worker中运行基本Three.js动画的演示： 示例：use-with-lib 请记住，某些与DOM相关的API在Worker中并不容易获得，因此如果您想使用更高级的Three.js功能（如纹理），则可能需要更多变通方法。 结论如果您大量使用画布的图形功能，OffscreenCanvas可以积极影响您的应用程序的性能。使工作人员可以使用画布渲染上下文增加了Web应用程序的并行性，并更好地利用了多核系统。 OffscreenCanvas在Chrome 69中没有标记。它也在 Firefox 中开发。由于其API与常规canvas元素非常一致，因此您可以轻松地对其进行特征检测并将其用作渐进增强，而不会破坏现有的应用程序或库逻辑。它在图形和动画与画布周围的DOM紧密相关的所有情况下都具有性能优势。]]></content>
      <categories>
        <category>性能优化</category>
      </categories>
      <tags>
        <tag>Canvas</tag>
        <tag>OffscreenCanvas</tag>
        <tag>Web Worker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据可视化之Earth NullSchool]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%2F%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%B9%8BEarth-NullSchool%2F</url>
    <content type="text"><![CDATA[本文转载自微信公众号 - LET（LET0-0） 今天来看一下 Earth NullSchool。 如上是该网站的一个动图效果，有兴趣的可以访问网站了解一个大概。作者在 github 上公布了自己的源码(和网站代码略有不同)，气象数据来自 NCEP，记得上周介绍的 AQICN 美国数据也是来自该网站，查了一下，该组织应该算是美国的国家气象局：National Centers for Environmental Prediction。 吸取上一篇的教训，直入主题。当然，想要了解风图原理的，可以看看之前写的可视化之风向图，需要对风图的数据和思路有一定了解，不然本文在理解上可能会有点吃力。 如上是具体数据列表，Mode 里显示支持 Air(风图)，Ocean(洋流)，Chem(化学物)，Particulates(颗粒物)，Height 指向不同高度，Overlay 表示叠加图层，比如风图+温度，洋流+浪高等，Control 为时间轴控件，比如历史数据。点击查看不同的数据效果，不难找到对应数据的 url 的规范。 气象数据采用的是 epak 格式，二进制流，代码中提供了数据规范。如下是数据规范和对应的 JSON 属性： 从 converter 属性，该数据来自 netcdf，而这个格式在之前的 Berkeley Earth 中也提到过，而原始数据是 grib 形式，以我的理解，里面应该有一个 grib2netcdf2epak 的过程，都提供了对应的转换工具。至于为何绕圈，我搜索了一下大概，知道一个大概优劣，但貌似都不绝对，在此就不妄论了。 对我个人而言，花时间最久的是如何以 localhost 方式获取该数据，因为它是 HTTPS 服务，做了 Referer 限制，对于我这个 Java 小白，绝对算得上是一个难题，不过反过来想，这不就是上天给我一个机会，让我学 JavaWeb 吗。花了不少时间，也请教了研发两位牛人，终于在 Jetty+Servlet 下实现了一个 Java 版的 Proxy，是本次最有收获的地方，代码一并奉上，见笑。 有了本地代理服务，对源码进行简单的修改，让其走代理，就实现了 localhost 的部署，两个参数:url 和 type。 在地图初始化的时候，先构建了全球格网，是一个 2：1 的矩形，下面是经过投影后的球状格网效果，主要用于后续获取任意点在地球上的位置，进而获取对应的风速(X,Y)，该方法提供了临近插值和双线性插值两种方式，该过程封装在 rectangularGrid 函数中。 接着，开始请求气象数据数据，解析过程封装在 decodeEpak 函数中：获取对应的 JSON 属性，全球风图是 720*360 大小，精度为 0.5℃，每个点有 X 和 Y 两个分量，在 X 和 Y 方向的向量，米单位。 万事俱备只欠东风——起风。这里有两点，第一，平移缩放时没有任何效果的，这是因为当 bounds 变化时，需要根据更新后的区域重新插值，计算量比较大，而插值的价值是精度上有保证，清晰，所以这是一个取舍。第二，不仅有一个风图，还有一个栅格底图，下图蓝绿色效果图，仔细看，和风的走势是吻合的，同时鼠标点击时，能获取对应位置的属性值。 对风场向量的插值过程是在 interpolateField 方式中实现的，这里逻辑如下：1:创建当前窗口对应的掩膜，如上图，全部区域都是黑色(0,0,0,0)，只有地球对应的区域颜色为(255, 0, 0, 1) ；2 随机生成风粒子，每一个粒子有五个属性，位置(XY),风速(UV)和生命周期(t)；3 类似一条扫描线，遍历可视区域的每一像素点，通过掩膜判断是否在有效范围内，如果该点有效，则获取其对应的经纬度；4 以全球网格为索引，获取该点对应的风场 Field，保存到对应的向量场 wind field，用于后面的风图效果；5 根据风场的强度，对应颜色表设置当前点的颜色强度，保存到 mask 掩膜中，这样 mask 在更新时用来判断区域是否可见，更新后则用于显示地图效果，也算是一图两用。如上是初始化的核心部分，里面有很多小的细节，比如风向，在平面上，XY 两个向量是直线，而在球面上，要调整为对应的经纬度，是曲线(distortion 函数)。 接着，每一帧根据风图的原理，实时更新：风粒子的当前位置，根据当前位置的风速获取下一帧的位置，数据更新(createField::field.move)后则开始渲染(animate.draw),这部分在风向图原理里面有很清楚的介绍，思路完全一致，这里只是把关键点和对应函数实现对应起来，关键还是要思路，如果有意愿不妨自己调试，便一目了然。 至于鼠标点击显示当前状态，代码我没有看，不过上述过程中已经提供了位置转换，数据存储，很容易获取映射关系。]]></content>
      <categories>
        <category>数据可视化</category>
      </categories>
      <tags>
        <tag>Canvas</tag>
        <tag>数据可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据可视化之风向图]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%2F%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%B9%8B%E9%A3%8E%E5%90%91%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[本文转载自微信公众号 - LET（LET0-0） 很多人都见过风向图，直观形象，也是地图数据和现实数据在可视化上很好的结合。 这是我见的第一个风向图，记得是 2012 年吧，当时觉得很有意思，作为一名技术人员，自然好奇它是如何做到的，是 Canvas 还是 SVG？但当时没深究。最近正好有人（大哥）提到了这个，不妨深入了解，一探究竟。于是乎，发现原来还有这么多玩法，大同小异，比如说这个，来自 earth.nullschool.net： 当然还有来自度娘开源的 echarts-x 的： 基本上，这三个效果图基本涵盖了目前风向图的技术点和功能点（我自己的看法，因为 windyty 是基于 earth.nullschool 写的，前者多了一个 worker 线程处理数据，而后者在 github 上开源）。不知道哪一个最对你的胃口？对我而言，图 1 简单易懂，可以快速掌握风向图的实现；图 2 是实时的全球风向数据，而且是二进制格式，是大数据传输的一个方案；图 3 则采用 WebGL 实时渲染，算是大数据渲染的一个方案，所以各有千秋。正好本文就结合这三个例子说一下其中处理好的地方，也是一个由易到难的过程。 原理乍看上去，多少会觉得无从下手。这是怎么做到的？其实吧，懂与不懂就是那一层纸，就看你愿不愿意戳破而已。我们先从数据说起。 首先介绍一下向量场（Vector Field）的概念。在维基百科的解释是：在向量分析中，向量场是把空间中的每一点指派到一个向量的映射。物理学中的向量场有风场、引力场、电磁场、水流场等等。如图，下面是一个二维的向量场，每一个点都是一个向量。 当然这是一个抽象的数学概念和表达，物理中的电磁场经常会用到它，在现实中其实也随处可见，比如下面这个有意思的磁场的向量表达，密集恐惧症的人请略过~ 同理，风场的抽象模型也是一个向量场：每一个点都有一个风速和方向，可以分解为在该点分别在 XY 方向上的向量（我们简化为 XY 两个方向，不考虑 Z，所以可惜不能听《龙卷风》了），则该向量则代表该点 X 方向和 Y 方向的速度。 如上图，是一个真实的风向图数据。简单来说，timestamp 代表当前数据的采集时间，（x0，y0，x1，y1）分别是经纬度的范围，而 grid 是该向量场的行列数，field 就是向量场中每一个点的速度值，如果是(0,0)则表示此点风平浪静。可能不同平台的风向图数据有一定差别，但都大同小异。 向量场和数据格式，直觉上，我们可以知道，就是把这些向量拟合成平滑线，可以形成如下一个真实的风向。 如何形成线，而且看上去全球范围内有总不能只有一阵风吧（让我想起了木星的大红斑，这场风在木星已经吹了至少 200 年从来没停过），这揭露了两个问题，1 向量场是离散点，而线是平滑，这里面有一个插值问题；2 更麻烦的是，这些线有好多好多连接的方式，都可以连接成线，有点类似等高线的算法，怎么连，看上去无从下手啊。 这是我看完数据后，自己觉得要实现风向效果时觉得需要解决的问题，感觉好难啊。怀着这个疑问进入梦乡，第二天 format 了一下 js 脚本，本地调试后，发现我的问题是对的，可是思路是错的。不要一上来就考虑这么多因素，而是基于当前的状态来解决当前的问题，就好比一道非常复杂的代数问题，或许通过几何方式反而可以很简单的解决。 不多废话了，尽管我觉得这些废话才是提高能力的最有价值的，解决问题不过是一个感悟过程的必然而已。好了，有了数据，看看“神诸葛”如何起风的吧。 举个例子，给你一个围棋棋盘（向量场），每一个格子就是一个向量，你随手拿一个棋子，随手（随机）放在一个格子上，这就是风的起点。下一回合（下一帧或下一秒），你根据当前格子的向量值（X 值和 Y 值）移动棋子，就是风在当前的风速下拖着常常的尾巴跳到下一个格子上的效果。这样，这个棋子会根据所在格子的向量值不停的移动，直到格子的向量值为零（风停）。 也就是说只要给一个起点，我就能刮起一股风来。那给你 5000 个棋子（起点），你就能刮起 5000 股风了。当然可能两股气流重叠，这时可能不太符合物理规律了，因为我们的思路下是各吹各的，不过谁关心呢。于是，基于每一帧状态的管理，我们可以很简单的模拟出风向图的效果。很简单巧妙吧。 如何实现好了，理论上我们知道该怎么做了，看看如何代码实现。我们也整理一下这个流程，把它们模块化。 今天就和围棋干上了，还是这个例子，首先呢就是数据，也就是棋盘和格子，也就是 Vector 和 Vector Field 这两个对象来方便数据的读取、管理等；其次，当然是棋子了，记录每一个棋子的生命周期，当前的位置，下一步的位置，也就是风上对应的每一个帧的位置信息，这个是 Particle 类来记录这些信息；最后，有了棋盘和棋子，还需要一个推手来落子，这里称作 MotionDisplay 把，负责管理每一回合（帧）下棋子对应棋盘的位置，这个类要做的事情很多：有多少个棋子、哪一个还收回、需要新增几个棋子（风粒子的管理），怎么在棋盘上放置（渲染）；等等，最后还少了一个，就是时钟啊，每一回合可是要读秒的哦，也就是 Animation。感觉例子比喻的很贴切啊，忍不住要放一张棋魂的图片来庆祝一下。 还是得上代码，不然显得不专业。下面先把上面提到的这些对象中一些关键的属性和方法说明一下，可以知道哪些关键的属性是由哪些类来管理，而一些关键的方法进行一个说明，大家可以先专注类和函数本身的内容，了解这个拼图的部分内容。最终会有一个初始化的函数来一个整体流程的介绍，这时大家会了解整个拼图的面貌。 向量比较简单，就是 X 和 Y 两个分量，其他的比如长度，角度这些方法就不在此赘述： 1234var Vector = function(x, y) &#123; this.x = x; this.y = y;&#125; 下面是向量场类读取 JSON 数据并解析： 1234567891011121314151617VectorField.read= function(data, correctForSphere) &#123; var field = []; var w = data.gridWidth; var h = data.gridHeight; for (var x = 0; x &lt; w; x++) &#123; field[x] = []; for (var y = 0; y &lt; h; y++) &#123; var vx = data.field[i++]; var vy = data.field[i++]; var v = new Vector(vx,vy); …… field[x][y] = v; &#125; &#125; var result = newVectorField(field,data.x0,data.y0,data.x1,data.y1); return result;&#125;; 如此，向量场已经布置完善，当然，对照 JSON 数据仔细看一下代码，有保存了经纬度的范围，行和列等信息，当然，该类中有其他几个函数没有在此列出，比如判断一个点是否在棋盘内，另外还有插值，因为每一个网格位置都是离散的，行和列都是整数，而现实中风的走向是连续的，可能在当前时刻的位置是分数，则需要根据临近的整数点的值插值获取当前点的一个近似值，这里采用的是双线性插值，取的周围四个点： 12345678910VectorField.prototype.bilinear= function(coord, a, b) &#123; var na = Math.floor(a); var nb = Math.floor(b); var ma = Math.ceil(a); var mb = Math.ceil(b); var fa = a - na; var fb = b - nb; return this.field[na][nb][coord] _ (1 - fa)_ (1 - fb) + this.field[ma][nb][coord] _ fa _ (1 - fb) + this.field[na][mb][coord] _ (1 - fa) _ fb + this.field[ma][mb][coord] _ fa _ fb;&#125;; 如上是向量和向量场的一些关键函数和属性。实现了读取数据，通过 getValue 函数获取任意一个位置（可以使小数）的速度的 X 和 Y 分量。 下面就是棋子了，每一回合棋子的位置也就是风在每一帧的位置： 1234567var Particle =function(x, y, age) &#123; this.x = x; this.y = y; this.oldX = -1; this.oldY = -1; this.age = age;&#125; 如上，XY 是当前的位置，而 old 则是上一帧的位置，age 是它的生命周期，有的时候棋子会被吃，起风了也有风停的那一刻，都是通过 age 来记录它还能活多久（每一帧减一）。 现在就开始介绍这只下棋的手了，看如何起风如何刮。 123456789varMotionDisplay = function(canvas, imageCanvas, field, numParticles,opt_projection) &#123; this.field = field; this.numParticles = numParticles; this.x0 = this.field.x0; this.x1 = this.field.x1; this.y0 = this.field.y0; this.y1 = this.field.y1; this.makeNewParticles(null, true); &#125;; 这是它的构造函数，用来记录向量场的信息（范围和速度向量），同时 numParticles 表示粒子数，即同时有多少条风线在地图上显示。projection 用于经纬度和向量场之间的映射换算。最后 makeNewParticles 则会构建 numParticles 个风，并随机赋给它们一个起点和生命周期，代码如下： 123456MotionDisplay.prototype.makeNewParticles= function(animator) &#123; this.particles = []; for (var i = 0; i &lt; this.numParticles;i++) &#123; this.particles.push(this.makeParticle(animator)); &#125;&#125;; 1234567MotionDisplay.prototype.makeParticle= function(animator) &#123; var a = Math.random(); var b = Math.random(); var x = a * this.x0 + (1 - a) *this.x1; var y = b _ this.y0 + (1 - b) _ this.y1; return new Particle(x,y,1 + 40 * Math.random()); &#125;; 如上是一个简单的创建粒子的过程：随机在经纬度（x，y）创建一个能够存活 1 + 40 *Math.random()帧的风，一共创建 numParticles 个这样的随机风。当然这里为了简单示意。并没有考虑随机数是否会超出范围等特殊情况。 对象都构建完成了，那每一帧这只手如何主持大局呢？两件事情：Update 和 Render。 1234MotionDisplay.prototype.animate= function(animator) &#123; this.moveThings(animator);//update this.draw(animator); // render&#125; 先看看如何更新： 1234567891011121314MotionDisplay.prototype.moveThings= function(animator) &#123; var speed = .01 _ this.speedScale /animator.scale; for (var i = 0; i &lt;this.particles.length; i++) &#123; var p = this.particles[i]; if (p.age &gt; 0 &amp;&amp;this.field.inBounds(p.x, p.y)) &#123; var a = this.field.getValue(p.x,p.y); p.x += speed _ a.x; p.y += speed * a.y; p.age--; &#125; else &#123; this.particles[i] = this.makeParticle(animator); &#125; &#125;&#125;; 如上，每一帧都根据速度*时间（帧）=距离来更新所有风粒子位置，同时检测如果 age 为负时，则重新创建一个来替换。 123456789101112131415161718192021222324MotionDisplay.prototype.draw= function(animator) &#123; var g = this.canvas.getContext('2d'); var w = this.canvas.width; var h = this.canvas.height; if (this.first) &#123; g.fillStyle = this.background; this.first = false; &#125; else &#123; g.fillStyle = this.backgroundAlpha; &#125; g.fillRect(dx, dy, w , h ); for (var i = 0; i &lt;this.particles.length; i++) &#123; var p = this.particles[i]; if (p.oldX != -1) &#123; g.beginPath(); g.moveTo(proj.x, proj.y); g.lineTo(p.oldX, p.oldY); g.stroke(); &#125; p.oldX = proj.x; p.oldY = proj.y; &#125;&#125;; 因为代码实在太长，给出的是关键步骤，先看后面的 stroke 过程，很明了，在 moveThings 的函数中我们可以得到上一帧的位置和当前帧的风粒子的位置，在这里连接起来形成了一段线。可以想象，随着帧数的增加，在有限的生命周期里面，这个折线就像贪吃蛇一样的增长:0-1-2-3-4……-n，则模拟出风的效果来下图是第一帧和第二帧的截图对比，仔细观察红线上面的那条风，这是前两帧的长度对比,或者在看一下洛杉矶附近的风，增长的比较明显，说明洛杉矶这几天风比较大哦，不信去看天气预报： 帧一 帧二 似乎这样就完美了，其实不是的。再一想，这条风有生命周期，到时候怎么从地图上把这条风擦除呢？如果不擦除岂不是就和灰一样堆满了，而且这个风明显有一种渐变的效果，这是怎么做到的？ 这里面是一个很棒的技巧，透明度 backgroundAlpha，这里采用和背景颜色一样的 RGB，但增加一个透明度为 0.02，fillRect 的作用就好比每一帧都贴一层这样的纸在上面，然后在上面画新的，则之前的变的有点暗了，旧的越来越暗，达到一种逼真的效果，同时也很好的处理了新老交替。 如此，一个基本的风向图就完成了。同样，当你以为一切都明了的时候，问题才刚刚开始。简单说一下下面两个要点：实时数据和 WebGL 渲染。WebGL 介绍有一些入门要求，可能不太容易明白，主要是气质（思路）。 实时数据代码读多了，上个段子环节一下氛围。上面例子的作者自称艺术家，想要用新的方式来思考数据，感受数据的美与乐趣。于是有了这个风向图，确实是一个很有趣的效果，但有一点不足点，作者主要是为了寻找数据的美，并没有提供一个有效的大数据实时性的方案。换句话说，这个范例还是处于看看而已的程度。一个风向图，你当然希望能在地图上实时的看到具体一个区域的风向和全球的整体效果，这就需要解决数据的高效传输。 下面这个例子则较好的考虑了这个问题，windytv 的作者是一位跳伞爱好者，每次跳伞前都要观察天气状况，特别是风向，于是乎就想到了这样一个风向图的应用。 如上是该网站的一个功能罗列，数据还是非常全的，数据来源是 GFS / NCEP / US National Weather Service，我发现里面的天气数据还是很全，而且风向只是其中一个部分（我相信以后国外的开放大数据+HTML5 下会有很多服务慢慢普及，不要错过哦）。在程序中，风向图的数据格式为 epak 的二进制格式,也是使用 ArrayBuffer 的方式来传输和解析的，对这块有兴趣的可以看看之前写的《ArrayBuffer 简析》。 还有一种很不错的方式就是图片： 注意上面黑条，其实是有八个像素的冗余，里面主要就是高宽，数据采集时间等信息，剩下的是一个全国范围的 360*180 的风向量数据。虽然该数据也不算是实时的，但可以实现六小时的更新，关键是可以进行高效的数据传输解析。 另外，用图片的好处是可以切片，比如精度不高下可以是全球的风向数据，精度高的时候，则可以更新局部的切片数据，和地图切片的思路完全一样，即避免插值的工作量，也可以更清晰的显示数据。因此，这可以算是对第一个范例一个很好的优化。另外，还是开源的哦，自己去找吧。 WebGL百度的风向图虽然很耗性能，但确实技术上有很多值得学习的地方，毕竟用 WebGL 渲染，它是如何实现生命周期和向量场的计算，还是有很多创新点。简单说一下几个关键处，能力有限，而且确实需要有一定的 WebGL 和 OpenGL 的了解，所以希望不要深究，注重别人的思路和方法即可。 先看看百度对外提供的接口使用方式： 12345678910111213surfaceLayers:[&#123; type: 'particle', distance: 3, size: [4096, 2048], particle: &#123; vectorField: field, color: 'white', speedScaling: 1, sizeScaling: 1, number: 512 * 512, motionBlurFactor: 0.99 &#125;&#125;] 用法比较简单，也是制定一个 particle，里面传入向量场数据，number 则是一帧中风的最大数，后面都是内部来控制。Echart-x 的代码稍微有点乱，最后我是用全局搜索才找到实现代码的。 Map3d负责图层创建和初始化的相关工作。 首先，当向量数据输入后，生成为一张等宽高的纹理 vectorFieldTexture，每一个向量（X，Y）就是该纹理上的一个点（RGBA），其中 X = R， Y = G， B=0 ，A=255.。则该纹理中每一个像素可以获取它的速度向量。 然后每一帧都会调用该图层的 UpDate 来更新渲染。 VectorFieldParticleSurface 这个就是一个风向图图层，记录风向图图层中的关键属性，关键是 update 函数，每一帧负责驱动状态更新。1234567891011121314update: function(deltaTime) &#123; this._particlePass.setUniform('velocityTexture',this.vectorFieldTexture); particlePass.attachOutput(this._particleTexture1); particlePass.setUniform('particleTexture', this._particleTexture0); particlePass.setUniform('deltaTime', deltaTime); particlePass.setUniform('elapsedTime', this._elapsedTime); particlePass.render(this.renderer,frameBuffer); this._particleMesh.material.set('particleTexture',this._particleTexture1); frameBuffer.attach(this.renderer.gl, this._thisFrameTexture); frameBuffer.bind(this.renderer); this.renderer.render(this._scene,this._camera);&#125; 可见，里面 Render 了两次，第一次是渲染到纹理（Render To Texture），其中还有一些时间参数，第二次才是渲染到场景。 这是在更新数据，将每一点对应的速度向量和位置参数传给 shader，而真正的运算都通过 Shader，直接操作显卡来完成渲染过程。参数准备完毕，结合下面的渲染过程来具体理解。 Shader首先在 ecx.vfParticle.particle.fragment 片元着色器： 123456789101112vec4 p =texture2D(particleTexture, v_Texcoord);if (p.w &gt; 0.0) &#123; vec4 vTex = texture2D(velocityTexture,p.xy); vec2 v = vTex.xy; v = (v - 0.5) * 2.0; p.z = length(v); p.xy += v * deltaTime / 50.0 *speedScaling; // Make the particle surface seamless p.xy = fract(p.xy); p.w -= deltaTime;&#125;gl_FragColor = p; 你会看到除了语法和 JS 的不同，里面的思路是一样的，首先从’velocityTexture’里面得到 xy，该纹理就是向量场中的信息，每一个点则对应的是速度向量，而 w 则表示生命周期。经过计算后把值赋给了 particleTexture 然后呢，如果你看懂了，就是如梦初醒的时候了，原来每一帧中，particleTexture 里面每一个点对应了当前风的位置，在 particle.fragment 中更新每一个点的位置，然后最终在场景中渲染出来。 1234voidmain()&#123; vec4 p = texture2D(particleTexture,texcoord); gl_Position = worldViewProjection _vec4(p.xy _ 2.0 - 1.0, 0.0, 1.0); &#125; 一个 WebGL 渲染风向图的大致思路，说的很不详细，关键是思路。技术的钻研，只要精益求精，总会有所收获。在这个过程中，我先想到风向图怎么实现的，等看明白了又想看看其他的脚本有何不同处，发现了数据实时性，也看到了百度的 WebGL 渲染的方式，可能也会有疏漏的地方，但总体感觉收获很大，面纱揭开后，也不再神秘。或者换句话说，风场，水流，重力场都可以按照这种方式来实现，只是计算公式上稍微调整一下就可以。]]></content>
      <categories>
        <category>数据可视化</category>
      </categories>
      <tags>
        <tag>Canvas</tag>
        <tag>数据可视化</tag>
        <tag>WebGL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据可视化之热力图]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%2F%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%B9%8B%E7%83%AD%E5%8A%9B%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[本文转载自微信公众号 - LET（LET0-0） 最近看了一下百度的热力图，通过百度地图，确实是一个实时大数据渲染的一个形象表达形式，正好借这个机会学习一下，刚买的机械键盘，发现有两个好处：每天不写点代码（或调试），感觉对不起这价钱啊，估计我之前买的所有键盘+鼠标花费总和都不如这个键盘贵；其次就是控制自己不再吃零食了，怕掉进键盘里心疼啊。 好了，热力图还是相对比较容易，我们主要讨论如下 3+1 点吧，主要是前三部分，后面只是简单分析一下百度热力图和个人的简单看法。热点图的实现参考了 SuperMap 的热点图和百度 Echarts 的热点图实现。 原理 实现 优化 百度热力图简述 原理 如上是全国范围内的截图，一看就能了解当前中国人口密集度。每个区域的形状不规则，而且还五颜六色。直觉上，我们会觉得每个区域都应该有一个位置点，还应该有一个缓冲范围，然后对这个范围内进行一个渐变效果。这个思路应该还是比较理性的，只是还是无法解释区域的不规则，但抽象了位置点（XY）和渐变（五颜六色）的数据概念。那我们再结合数据，看看我们的推理是否准确。 这是一个示例数据，可见每一个 HeatPoint 由三部分组成(X,Y,Weight)。这个和我们之前分析的比较类似，每一个热点都有一个位置和权重，权重越大，则该点越显著，也就代表其渐变的一个衰变因素。不规则的区域又是如何形成的？看完代码后发现，是每个热点各管各的，然后相互叠加影响，形成了最终具有真实意义的奇形怪状的热点图。想想也是，不然好看不实用，那热点图的设计也就本末倒置了。另外还有一个半径属性，主要是缓冲区的半径，表示该热点的影响范围，通常我们认为所有热点的影响范围即半径都是一样的，只是权重不同，这也是为了处理的方便。 打个比方，下雨天的池塘，每一个雨滴都会引起一个涟漪，这就相当于一个热点，位置不同，雨滴的大小速度质量等并不完全一样，因此具有不同的权重，但在水面上，相互影响，形成了很多不同的形状，而水波的密集度可以用渐变来体现。这样，我们则把每一个个离散点，通过一个缓冲区，转变为连续的面，进而对其进行可视化展现。 当然，在数据上需要多提一点，实际中，因为热点数据量非常大，所以在不同级别下的数据会有优化，比如全国范围内（大）的数据比较粗略（小），而区域范围内（小）数据精细（大）。这里面有一个抽稀和聚类的处理（个人感觉应该是这个思路），这是数据处理层面的问题，我们下面还是专注可视化方面的问题。 实现这些代码都比较简单，如果你对 canvas 有一定基础，相信也能明白，主要是看思路。首先就是对所有点进行一次筛选和统计，只保留屏幕范围内的热点，并根据权重获取当前最大和最小权重。这样我们获取了一个[minWeight，maxWeight]以及所有需要处理的 drawPoints 数组，为下面的渲染准备好数据。 渲染的过程其实就是对每一个热点权重范围内的点进行颜色的更新，颜色包括两个部分：RGB 和 Alpha。而渲染过程也分为两个过程：权重的计算和权重对应的颜色（RGB + Alpha）。 首先，权重的计算是一个插值的过程，根据权重值和范围值（距离热点的距离）的算法，你可以根据具体的需要选择合适的算法，而计算主要有两种情况，当前点还没有任何权重值；累加当前点的权重值。点越密，累加后的权重值就越高，则可以用权重值高的风格（红色）突出。其次就是根据权重值获取对应的颜色，这里会有一个颜色表，根据不同的权重值，采用具体的差值算法获取对应的颜色。 这样则完成了热点图的渲染，这里需要注意的是，两个 for 循环是对热点的行列的遍历，本身是一个矩阵范围，而热点本身的范围应该是一个圆，因此在 for 循环中需要判断是否在圆内。最终效果如下图： 优化如上就是热点图的原理和实现，基本上实现都大同小异。不知道你看出来有什么问题了没有？性能！ 这个实现有一个特点，假设有 N 个热点，权重假设是(0,1)之间的平均值 0.5，半径假设为 R(像素单位),那一共要有 N _ 0.5 _ R _ R _ 4（4 个象限），这个计算量是惊人的，和 N 以及 R 的平方是线性增长。另外一个特点，在 for 循环中的规则都是一致的。 这就让我们想到，如何能够进行优化，答案就是批次和模板。在开始前，我们先说两个技术点。 Canvas 渐变填充 如上是伪代码，最终是在 canvas 上绘制了一个圆，但本身是从黑到白的渐变，同时阴影在 x 轴上偏移 d 个像素，这样，该代码生成了如下一张图片，我们称它为权重图，暂时不解释，只需要明白这段代码生成该图的过程即可。 Canvas 色带 这里主要有两个函数： createLinearGradient()创建线性的渐变对象 addColorStop() 方法规定不同的颜色，以及在 gradient 对象中的何处定位颜色 这样，我们便创建了一个色带，就是如上这样一个效果，当然我们也可以根据自己的需要，定义一个彩色色带，就想我们平时所见的调色板中的颜色色带一样。这里比较宽，主要是给大家看一下效果，真正程序中，宽度只需要一个像素就可以。 实例化不知道大家这时候是否发现了里面的原理和巧妙之处？ 打个比方，我一直想买一个印章，这样每次买书的时候，就不用自己一笔一划的来写了，字写得比人还丑，这可以理解（不过最后还是没买，因为最后连书也买不起了）。假如我有了印章，这样每次就不用自己写了，直接盖章多省事啊，而且还一模一样。 这里，假设这个章是圆形的，它就是一个模板，对应的就是创建好的渐变填充的纹理。以前我们需要对热点缓冲区内的所有点都进行计算，计算出权重值，现在只需要以该热点为圆心盖一下，则把该热点范围内所有点的权重值都写上去了。 于是，逐个把所有热点都盖章，这样权重值不是都有了嘛，啪啪啪的声音就是爽。但这有一个问题，热点之间的相互影响怎么处理？这是需要叠加效果的，而不是后盖的章覆盖前者的效果。这里在盖章的时候增加一个透明度的属性，谁的权重大，谁的透明度就小，这样就可以叠加效果了，之前写的风向图的轨迹也是这个思路，还记得吗？下面是逐次盖章（贴图）的代码实现，大家过一遍，都是一个思路。 这样之后，我们就有了一个“热力图”了，不过略有遗憾，因为它是黑白相机拍出来的，都是 0~255 的灰度值，也就是权重信息。这样，我们就需要根据之前创建的色带来对它进行上色的过程了 可见，通过模板，我们可以极大的减少计算量，渲染也是批次的，而不是逐点赋值。这样我们可以根据不同的算法来创建对应的模板，实现不同的热点风格。下面是百度热力图采用这个方式实现的思路。 百度热力图&amp;总结不知不觉又写了这么多，就压缩一下篇幅吧。如下，是百度热力图八小时的请求队列，从 v 的属性可以看出来是小时单位，而 xyz 和地图行列号一致。如果想要叠加百度热力图的，就可以按照这个思路来加载热力图层了。 总体来说，个人觉得有两点收获：1 功能的实现不是完结，而是开始，方能深入掌握其中，就好比一锅汤，精华都在下面，沉得住寂寞，肯定有所收获。2 热力图的技术点都不难，一看便知，但不看还真不知道，这些技术点看起来没关系，但结合好了性能的提升非常明显。所以，见的多了经验就多。 今天圣诞节了，每年圣诞节我都会买一本书，然后写上”Merry Christmas to me”，然后送给自己，能看到这的人也都是真爱，再唠叨几句吧：昨天听了一个 deliberate practice 的概念，讲的是同等时间下，业余爱好者喜欢不断练习自己熟悉的动作，而专业选手则会专注在自己不熟悉但有机会掌握的动作，这一块在心理学中成为 panic zone，属于你知道，但不精通的部分。个人觉得收获很大，如何更好的发挥时间价值，这也是我，作为一个老人家需要调整的地方。]]></content>
      <categories>
        <category>数据可视化</category>
      </categories>
      <tags>
        <tag>Canvas</tag>
        <tag>数据可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图解 ArrayBuffers 和 SharedArrayBuffers]]></title>
    <url>%2F%E5%89%8D%E7%AB%AF%E7%AC%94%E8%AE%B0%2F%E5%9B%BE%E8%A7%A3-ArrayBuffers-%E5%92%8C-SharedArrayBuffers%2F</url>
    <content type="text"><![CDATA[ArrayBuffer 是如何工作的ArrayBuffer 跟其它 JavaScript 数组差不多，但是不是所有 JavaScript 类型都可以放进去，比如对象、字符串。你唯一可以放进去的只有字节（可以用数字表示） 需要澄清的一点是，你事实上不是直接把这个字节到 ArrayBuffer 里就行了，ArrayBuffer 并不知道字节有多长，该用多少位去存 ArrayBuffer 仅仅是一个个 0/1 组成的串，它不知道第一个元素和第二个元素的分割点 为了提供必要的上下文信息，把 ArrayBuffer 分块，我们需要把它包裹到视图里，这些数据的视图可以通过带类型的数组添加，已经支持很多种类型的数组了 例如，你可以用一个 Int8 类型的数组把 0/1 串分割成 8 位一组的序列 或者你可以用一个无符的 Int16 类型数组，把它分割成 16 位一组的序列，可以把它当作无符整型处理 甚至你可以在同一个基础 buffer 上同时处理多种视图，不同视图在相同操作下会返回不同的结果 例如，如果我们从某个 ArrayBuffer 的 Int8 视图得到第 0 和第 1 个元素的值，在 Uint16 视图下，第 0 个元素与其有相同二进制位值，但是得到的值也会不一样 这种方式下，ArrayBuffer 几乎是扮演原始内存角色了，它模拟内存的各种跟 C 语言里类似的操作 你可能纳闷了，为什么不让开发者直接操纵内存而是采用这个抽象层。因为直接操作内存会有安全风险，这个以后的文章会讲 什么是 SharedArrayBuffer为了说明白 SharedArrayBuffers，我需要稍微解释下并行运行代码和 JavaScript 的关系 为了更快运行代码或者更更快响应用户事件，你可能会让代码并行运行，为了做到这点，你需要分割工作 一个典型的应用中，所有的工作都由一个单独的主线程处理，这点我之前提到过……这个主线程就像一个全栈工程师，掌管着 JavaScript、DOM 和 视图 任何能够从主线程负载减少工作的方法都对代码运行效率有帮助，某些情况下，ArrayBuffers 可以减少大量应该由主线程做的工作 但是也有些时候减少主线程负载是远远不够的，有时你需要增援，你需要分割你的任务 大多数语言里，这种分割工作的方法可以使用多线程实现，这就像很多人同时在一个项目里工作。如果你可以完美地把任务分割为多个独立的部分，你可以分给不同的线程，然后，这些线程就同时各种独立执行这些任务 在 JavaScript 里，你可以借助 web worker 做这种事，这些 web workers 跟其它语言的线程还是有些区别的，默认它们不能共享内存 这意味着如果你想分配你的任务给别的线程，你需要完整把任务复制过去，这可以通过 postMessage 实现 postMessage 把你传给它的任何对象都序列化，发送到其它 web worker，然后那边接收后反序列化并放进内存 这个过程是非常慢的 某些类型数据（如 ArrayBuffers）你可以通过移动内存的方式实现，这意味着把某个特定区域的内存移过去后其它 web worker 就可以直接访问了 但是，之前的 web worker 就无法访问了 对于某些场景这是实用的，但是也有很多场景对性能要求高，你只能使用共享的内存 而这就是 SharedArrayBuffers 为你提供的 有了 SharedArrayBuffer 后，多个 web worker 就可以同时读写同一块内存了 你再也不需要 postMessage 伴有时延的通信了，多个 web worker 对数据访问都没有时延了 当然，这种同时访问也有风险，会产生竞争条件 SharedArrayBuffers 支持情况所有主流浏览器都将会支持 SharedArrayBuffers Safari 10.1 已经支持了，Firefox 和 Chrome 也会很快支持并发布，Edge 会在他们秋季 Windows 更新的时候发布 即使所有主流浏览器都支持了，我们也不希望开发者直接使用它们，事实上，我们是反对的。你应该只使用更高级的封装好的抽象层接口 我们期盼的是 JavaScript 库开发者可以提供更简单安全的方法来使用 SharedArrayBuffers 而且，一旦 SharedArrayBuffers 内置到平台中，WebAssembly 可以通过它实现多线程，到那时候你就可以使用类似 Rust 的多线程语言轻松玩转多线程了]]></content>
      <categories>
        <category>前端笔记</category>
      </categories>
      <tags>
        <tag>ArrayBuffers</tag>
        <tag>SharedArrayBuffers</tag>
      </tags>
  </entry>
</search>
